{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Zhangdc123/shop/blob/main/notebooks/football-ai.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JFS_cSAqNKHi"
      },
      "source": [
        "# Football AI\n",
        "\n",
        "---\n",
        "\n",
        "[![GitHub](https://badges.aleen42.com/src/github.svg)](https://github.com/roboflow/sports)\n",
        "[![Roboflow](https://raw.githubusercontent.com/roboflow-ai/notebooks/main/assets/badges/roboflow-blogpost.svg)](https://blog.roboflow.com/camera-calibration-sports-computer-vision/)\n",
        "[![YouTube](https://badges.aleen42.com/src/youtube.svg)](https://www.youtube.com/watch?v=aBVGKoNZQUw)\n",
        "\n",
        "‰ΩøÁî®ËÆ°ÁÆóÊú∫ËßÜËßâÂíåÊú∫Âô®Â≠¶‰π†Ë∑üË∏™ÁêÉÂëò,Âπ∂Á°ÆÂÆöÊâÄÂ±ûÁêÉÈòü,‰ª•ÂèäËÆ°ÁÆóË∂≥ÁêÉ‰ΩçÁΩÆ. ‰ΩøÁî®ËÆ°ÁÆóÊú∫Êù•ÂàÜÊûêÊØîËµõÁä∂ÊÄÅ\n",
        "\n",
        "![football AI diagram](https://media.roboflow.com/notebooks/examples/football-ai-diagram.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5qXFCSup2T0L"
      },
      "source": [
        "# ‰∏Ä„ÄÅÂáÜÂ§áÂ∑•‰Ωú"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l0NnZCmC2Kmx"
      },
      "source": [
        "### Ëé∑Âæó API keys\n",
        "\n",
        "- ÊâìÂºÄ [`HuggingFace Settings`](https://huggingface.co/settings)  Â§çÂà∂API\n",
        "- ÊâìÂºÄ[`Roboflow Settings`](https://app.roboflow.com/settings/api) Â§çÂà∂API\n",
        "- Âú® Colab‰∏≠, ÁÇπÂáªÂ∑¶‰æßÁöÑ `Secrets` (üîë).\n",
        "    - Á≤òË¥¥ HuggingFace Token ÂëΩÂêç‰∏∫ `HF_TOKEN`.\n",
        "    - Á≤òË¥¥ Roboflow API Key ÂëΩÂêç‰∏∫ `ROBOFLOW_API_KEY`."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"HF_TOKEN\"] = userdata.get(\"HF_TOKEN\")\n",
        "os.environ[\"ROBOFLOW_API_KEY\"] = userdata.get(\"ROBOFLOW_API_KEY\")"
      ],
      "metadata": {
        "id": "WQX_3KmAczkW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "og_H-sidUcaX"
      },
      "source": [
        "### Á°Æ‰øùgpuÊ≠£Â∏∏Â∑•‰Ωú\n",
        "\n",
        "Let's make sure that we have access to GPU. We can use `nvidia-smi` command to do that. In case of any problems navigate to `Edit` -> `Notebook settings` -> `Hardware accelerator`, set it to `GPU`, and then click `Save`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_8qxMYQZmXgz"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZXYNzU4tH4Q"
      },
      "source": [
        "## ‰∏ãËΩΩ‰æùËµñÈ°π\n",
        "\n",
        "**Note:**  ÁâàÊú¨Êä•ÈîôÂèØÂøΩÁï•"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JgZIoz0YTvV-"
      },
      "outputs": [],
      "source": [
        "!pip install -q gdown inference-gpu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zrE633rgXSZK"
      },
      "source": [
        "**Note:** Ë∞ÉÁî®github‰∏äËÆ≠ÁªÉÂ•ΩÁöÑÊ®°Âûã"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VcuIp4oXBClh"
      },
      "outputs": [],
      "source": [
        "!pip install -q git+https://github.com/roboflow/sports.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWAljqbWYJPX"
      },
      "source": [
        "**Note:** Á°Æ‰øùÁâàÊú¨È´ò‰∫é `0.23.0`"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip list | grep supervision"
      ],
      "metadata": {
        "id": "TOk2rwjbckZN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1WKBNI87YrEt"
      },
      "source": [
        "**Note:** ‰ªé [DFL - Bundesliga Data Shootout](https://www.kaggle.com/competitions/dfl-bundesliga-data-shootout) ‰∏ãËΩΩÊµãËØïËßÜÈ¢ë\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "boWlJuuMUfom"
      },
      "outputs": [],
      "source": [
        "!gdown -O \"0bfacc_0.mp4\" \"https://drive.google.com/uc?id=12TqauVZ9tLAv8kWxTTBFWtgt2hNQ4_ZF\"\n",
        "!gdown -O \"2e57b9_0.mp4\" \"https://drive.google.com/uc?id=19PGw55V8aA6GZu5-Aac5_9mCy3fNxmEf\"\n",
        "!gdown -O \"08fd33_0.mp4\" \"https://drive.google.com/uc?id=1OG8K6wqUw9t7lp9ms1M48DxRhwTYciK-\"\n",
        "!gdown -O \"573e61_0.mp4\" \"https://drive.google.com/uc?id=1yYPKuXbHsCxqjA9G-S6aeR2Kcnos8RPU\"\n",
        "!gdown -O \"121364_0.mp4\" \"https://drive.google.com/uc?id=1vVwjW1dE1drIdd4ZSILfbCGPD4weoNiu\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Rq5-SX9WfsY"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"ONNXRUNTIME_EXECUTION_PROVIDERS\"] = \"[CUDAExecutionProvider]\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eVlyqi7pVFDo"
      },
      "source": [
        "#‰∫å„ÄÅÊ£ÄÊµãÁêÉ ËøêÂä®Âëò ÂÆàÈó®Âëò Ë£ÅÂà§"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZV9voyVS6Aqi"
      },
      "outputs": [],
      "source": [
        "from inference import get_model\n",
        "from google.colab import userdata\n",
        "\n",
        "ROBOFLOW_API_KEY = userdata.get('ROBOFLOW_API_KEY')\n",
        "PLAYER_DETECTION_MODEL_ID = \"football-players-detection-3zvbc/11\"\n",
        "PLAYER_DETECTION_MODEL = get_model(model_id=PLAYER_DETECTION_MODEL_ID, api_key=ROBOFLOW_API_KEY)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Â±ïÁ§∫ËßÜÈ¢ëÁ¨¨‰∏ÄÂ∏ß Á°Æ‰øùËßÜÈ¢ëÊ≠£Á°ÆÂä†ËΩΩ"
      ],
      "metadata": {
        "id": "ahwrTCOJkl7W"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zz-hd4mdZ4UD"
      },
      "outputs": [],
      "source": [
        "import supervision as sv\n",
        "\n",
        "SOURCE_VIDEO_PATH = \"/content/573e61_0.mp4\"\n",
        "\n",
        "frame_generator = sv.get_video_frames_generator(SOURCE_VIDEO_PATH)\n",
        "frame = next(frame_generator)\n",
        "\n",
        "sv.plot_image(frame)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Âæ™ÁéØÊ£ÄÊµãÊØè‰∏ÄÂ∏ß‰∏≠ÁöÑÁêÉÂëòÔºåË£ÅÂà§ÂíåÁêÉ"
      ],
      "metadata": {
        "id": "RVErNu4FkwE3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "duGEOk-j4n4i"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "import supervision as sv\n",
        "\n",
        "SOURCE_VIDEO_PATH = \"/content/08fd33_0.mp4\"\n",
        "TARGET_VIDEO_PATH = \"/content/08fd33_0_result_1.mp4\"\n",
        "\n",
        "box_annotator = sv.BoxAnnotator(\n",
        "    color=sv.ColorPalette.from_hex(['#FF8C00', '#00BFFF', '#FF1493', '#FFD700']),\n",
        "    thickness=2\n",
        ")\n",
        "label_annotator = sv.LabelAnnotator(\n",
        "    color=sv.ColorPalette.from_hex(['#FF8C00', '#00BFFF', '#FF1493', '#FFD700']),\n",
        "    text_color=sv.Color.from_hex('#000000')\n",
        ")\n",
        "\n",
        "video_info = sv.VideoInfo.from_video_path(SOURCE_VIDEO_PATH)\n",
        "video_sink = sv.VideoSink(TARGET_VIDEO_PATH, video_info=video_info)\n",
        "frame_generator = sv.get_video_frames_generator(SOURCE_VIDEO_PATH)\n",
        "\n",
        "with video_sink:\n",
        "    for frame in tqdm(frame_generator, total=video_info.total_frames):\n",
        "\n",
        "        result = PLAYER_DETECTION_MODEL.infer(frame, confidence=0.3)[0]\n",
        "        detections = sv.Detections.from_inference(result)\n",
        "\n",
        "        labels = [\n",
        "            f\"{class_name} {confidence:.2f}\"\n",
        "            for class_name, confidence\n",
        "            in zip(detections['class_name'], detections.confidence)\n",
        "        ]\n",
        "\n",
        "        annotated_frame = frame.copy()\n",
        "        annotated_frame = box_annotator.annotate(annotated_frame, detections)\n",
        "        annotated_frame = label_annotator.annotate(annotated_frame, detections, labels=labels)\n",
        "        video_sink.write_frame(annotated_frame)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-4F9NB48U1_"
      },
      "source": [
        "## ‰∏çÂêåÈ£éÊ†ºÁöÑÂ±ïÁ§∫ÔºàÈúÄË¶ÅÊèêÂâçËøêË°å ÂêéÈù¢‰ºöÁî®Âà∞Áõ∏ÂÖ≥Êï∞ÊçÆÔºâ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AWoDdvikt4TR"
      },
      "outputs": [],
      "source": [
        "import supervision as sv\n",
        "from tqdm import tqdm\n",
        "\n",
        "SOURCE_VIDEO_PATH = \"/content/08fd33_0.mp4\"\n",
        "TARGET_VIDEO_PATH = \"/content/08fd33_0_result_2.mp4\"\n",
        "BALL_ID = 0\n",
        "\n",
        "ellipse_annotator = sv.EllipseAnnotator(\n",
        "    color=sv.ColorPalette.from_hex(['#00BFFF', '#FF1493', '#FFD700']),\n",
        "    thickness=2\n",
        ")\n",
        "triangle_annotator = sv.TriangleAnnotator(\n",
        "    color=sv.Color.from_hex('#FFD700'),\n",
        "    base=25,\n",
        "    height=21,\n",
        "    outline_thickness=1\n",
        ")\n",
        "\n",
        "video_info = sv.VideoInfo.from_video_path(SOURCE_VIDEO_PATH)\n",
        "frame_generator = sv.get_video_frames_generator(SOURCE_VIDEO_PATH)\n",
        "\n",
        "\n",
        "with sv.VideoSink(target_path=TARGET_VIDEO_PATH, video_info=video_info) as sink:\n",
        "    for frame in tqdm(frame_generator, total=video_info.total_frames):\n",
        "\n",
        "        result = PLAYER_DETECTION_MODEL.infer(frame, confidence=0.3)[0]\n",
        "        detections = sv.Detections.from_inference(result)\n",
        "\n",
        "        ball_detections = detections[detections.class_id == BALL_ID]\n",
        "        ball_detections.xyxy = sv.pad_boxes(xyxy=ball_detections.xyxy, px=10)\n",
        "\n",
        "        all_detections = detections[detections.class_id != BALL_ID]\n",
        "        all_detections = all_detections.with_nms(threshold=0.5, class_agnostic=True)\n",
        "\n",
        "        all_detections.class_id -= 1\n",
        "\n",
        "        annotated_frame = frame.copy()\n",
        "        annotated_frame = ellipse_annotator.annotate(\n",
        "            scene=annotated_frame,\n",
        "            detections=all_detections)\n",
        "        annotated_frame = triangle_annotator.annotate(\n",
        "            scene=annotated_frame,\n",
        "            detections=ball_detections)\n",
        "\n",
        "        sink.write_frame(annotated_frame)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rNRVUGG4nz_J"
      },
      "source": [
        "## Â¢ûÂä†ÁêÉÂëòÁºñÂè∑ÁöÑÂ±ïÁ§∫"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ixZlM06Gmae"
      },
      "outputs": [],
      "source": [
        "import supervision as sv\n",
        "from tqdm import tqdm\n",
        "\n",
        "SOURCE_VIDEO_PATH = \"/content/121364_0.mp4\"\n",
        "TARGET_VIDEO_PATH = \"/content/121364_0_result_3.mp4\"\n",
        "BALL_ID = 0\n",
        "\n",
        "ellipse_annotator = sv.EllipseAnnotator(\n",
        "    color=sv.ColorPalette.from_hex(['#00BFFF', '#FF1493', '#FFD700']),\n",
        "    thickness=2\n",
        ")\n",
        "label_annotator = sv.LabelAnnotator(\n",
        "    color=sv.ColorPalette.from_hex(['#00BFFF', '#FF1493', '#FFD700']),\n",
        "    text_color=sv.Color.from_hex('#000000'),\n",
        "    text_position=sv.Position.BOTTOM_CENTER\n",
        ")\n",
        "triangle_annotator = sv.TriangleAnnotator(\n",
        "    color=sv.Color.from_hex('#FFD700'),\n",
        "    base=25,\n",
        "    height=21,\n",
        "    outline_thickness=1\n",
        ")\n",
        "\n",
        "tracker = sv.ByteTrack()\n",
        "tracker.reset()\n",
        "\n",
        "video_info = sv.VideoInfo.from_video_path(SOURCE_VIDEO_PATH)\n",
        "frame_generator = sv.get_video_frames_generator(SOURCE_VIDEO_PATH)\n",
        "\n",
        "with sv.VideoSink(target_path=TARGET_VIDEO_PATH, video_info=video_info) as sink:\n",
        "    for frame in tqdm(frame_generator, total=video_info.total_frames):\n",
        "\n",
        "        result = PLAYER_DETECTION_MODEL.infer(frame, confidence=0.3)[0]\n",
        "        detections = sv.Detections.from_inference(result)\n",
        "\n",
        "        ball_detections = detections[detections.class_id == BALL_ID]\n",
        "        ball_detections.xyxy = sv.pad_boxes(xyxy=ball_detections.xyxy, px=10)\n",
        "\n",
        "        all_detections = detections[detections.class_id != BALL_ID]\n",
        "        all_detections = all_detections.with_nms(threshold=0.5, class_agnostic=True)\n",
        "        all_detections.class_id -= 1\n",
        "\n",
        "        all_detections = tracker.update_with_detections(detections=all_detections)\n",
        "\n",
        "        labels = [\n",
        "            f\"#{tracker_id}\"\n",
        "            for tracker_id in all_detections.tracker_id\n",
        "        ]\n",
        "\n",
        "        annotated_frame = frame.copy()\n",
        "        annotated_frame = ellipse_annotator.annotate(\n",
        "            scene=annotated_frame,\n",
        "            detections=all_detections)\n",
        "        annotated_frame = label_annotator.annotate(\n",
        "            scene=annotated_frame,\n",
        "            detections=all_detections,\n",
        "            labels=labels)\n",
        "        annotated_frame = triangle_annotator.annotate(\n",
        "            scene=annotated_frame,\n",
        "            detections=ball_detections)\n",
        "\n",
        "        sink.write_frame(annotated_frame)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1smkPKfYm00"
      },
      "source": [
        "#‰∏â„ÄÅÂ∞ÜÁêÉÂëòÂàÜÈòü\n",
        "\n",
        "![football AI diagram](https://media.roboflow.com/notebooks/examples/football-ai-team-clustering.png)\n",
        "\n",
        "**Note:** ÊØèÁßíÈááÊ†∑‰∏ÄÂ∏ßÂπ∂Êî∂ÈõÜÁêÉÂëòÁöÑÂàáÁâá"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mr2smM9fMTSO"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "SOURCE_VIDEO_PATH = \"/content/08fd33_0.mp4\"\n",
        "PLAYER_ID = 2\n",
        "STRIDE = 30\n",
        "\n",
        "frame_generator = sv.get_video_frames_generator(\n",
        "    source_path=SOURCE_VIDEO_PATH, stride=STRIDE)\n",
        "\n",
        "crops = []\n",
        "for frame in tqdm(frame_generator, desc='collecting crops'):\n",
        "    result = PLAYER_DETECTION_MODEL.infer(frame, confidence=0.3)[0]\n",
        "    detections = sv.Detections.from_inference(result)\n",
        "    detections = detections.with_nms(threshold=0.5, class_agnostic=True)\n",
        "    detections = detections[detections.class_id == PLAYER_ID]\n",
        "    players_crops = [sv.crop_image(frame, xyxy) for xyxy in detections.xyxy]\n",
        "    crops += players_crops\n",
        "sv.plot_images_grid(crops[:100], grid_size=(10, 10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8COwN7TweZpK"
      },
      "source": [
        "**Note:** Áé∞Âú®ÈÄöËøá [SigLIP](https://huggingface.co/docs/transformers/en/model_doc/siglip) ËÆ°ÁÆóÂàáÁâáÁöÑÊï∞Â≠óÂêëÈáè"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PLcvVFrbOey8"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoProcessor, SiglipVisionModel\n",
        "\n",
        "SIGLIP_MODEL_PATH = 'google/siglip-base-patch16-224'\n",
        "\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "EMBEDDINGS_MODEL = SiglipVisionModel.from_pretrained(SIGLIP_MODEL_PATH).to(DEVICE)\n",
        "EMBEDDINGS_PROCESSOR = AutoProcessor.from_pretrained(SIGLIP_MODEL_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wrn67xnEQZzM"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from more_itertools import chunked\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "crops = [sv.cv2_to_pillow(crop) for crop in crops]\n",
        "batches = chunked(crops, BATCH_SIZE)\n",
        "data = []\n",
        "with torch.no_grad():\n",
        "    for batch in tqdm(batches, desc='embedding extraction'):\n",
        "        inputs = EMBEDDINGS_PROCESSOR(images=batch, return_tensors=\"pt\").to(DEVICE)\n",
        "        outputs = EMBEDDINGS_MODEL(**inputs)\n",
        "        embeddings = torch.mean(outputs.last_hidden_state, dim=1).cpu().numpy()\n",
        "        data.append(embeddings)\n",
        "\n",
        "data = np.concatenate(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C1QUD1X25faA"
      },
      "source": [
        "**Note:** ‰ΩøÁî® [UMAP](https://github.com/lmcinnes/umap), ÈôçÁª¥Â∞Ü `(N, 768)` ÂéãÁº©‰∏∫ `(N, 3)` ‰ΩøÁî® [KMeans](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html)ÂàÜ‰∏∫‰∏§Èòü"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0EXV02O3SWsX"
      },
      "outputs": [],
      "source": [
        "import umap\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "REDUCER = umap.UMAP(n_components=3)\n",
        "CLUSTERING_MODEL = KMeans(n_clusters=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bfrRj4_PS1HD"
      },
      "outputs": [],
      "source": [
        "projections = REDUCER.fit_transform(data)\n",
        "clusters = CLUSTERING_MODEL.fit_predict(projections)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_gqJjBu6IRU"
      },
      "source": [
        "**Note:** ÂèØËßÜÂåñÁªìÊûúÔºåÁÇπÂáªÊòæÁ§∫ÂéüÂõæ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zXWLoCBtfPDH"
      },
      "outputs": [],
      "source": [
        "import plotly.graph_objects as go\n",
        "import numpy as np\n",
        "from typing import Dict, List\n",
        "from IPython.core.display import display, HTML\n",
        "from PIL import Image\n",
        "import base64\n",
        "from io import BytesIO\n",
        "\n",
        "\n",
        "def pil_image_to_data_uri(image: Image.Image) -> str:\n",
        "    buffered = BytesIO()\n",
        "    image.save(buffered, format=\"PNG\")\n",
        "    img_str = base64.b64encode(buffered.getvalue()).decode(\"utf-8\")\n",
        "    return f\"data:image/png;base64,{img_str}\"\n",
        "\n",
        "\n",
        "def display_projections(\n",
        "    labels: np.ndarray,\n",
        "    projections: np.ndarray,\n",
        "    images: List[Image.Image],\n",
        "    show_legend: bool = False,\n",
        "    show_markers_with_text: bool = True\n",
        ") -> None:\n",
        "    image_data_uris = {f\"image_{i}\": pil_image_to_data_uri(image) for i, image in enumerate(images)}\n",
        "    image_ids = np.array([f\"image_{i}\" for i in range(len(images))])\n",
        "\n",
        "    unique_labels = np.unique(labels)\n",
        "    traces = []\n",
        "    for unique_label in unique_labels:\n",
        "        mask = labels == unique_label\n",
        "        customdata_masked = image_ids[mask]\n",
        "        trace = go.Scatter3d(\n",
        "            x=projections[mask][:, 0],\n",
        "            y=projections[mask][:, 1],\n",
        "            z=projections[mask][:, 2],\n",
        "            mode='markers+text' if show_markers_with_text else 'markers',\n",
        "            text=labels[mask],\n",
        "            customdata=customdata_masked,\n",
        "            name=str(unique_label),\n",
        "            marker=dict(size=8),\n",
        "            hovertemplate=\"<b>class: %{text}</b><br>image ID: %{customdata}<extra></extra>\"\n",
        "        )\n",
        "        traces.append(trace)\n",
        "\n",
        "    # Calculate shared range for cube appearance\n",
        "    all_axes = projections\n",
        "    min_val = np.min(all_axes)\n",
        "    max_val = np.max(all_axes)\n",
        "    padding = (max_val - min_val) * 0.05\n",
        "    axis_range = [min_val - padding, max_val + padding]\n",
        "\n",
        "    fig = go.Figure(data=traces)\n",
        "    fig.update_layout(\n",
        "        scene=dict(\n",
        "            xaxis=dict(title='X', range=axis_range),\n",
        "            yaxis=dict(title='Y', range=axis_range),\n",
        "            zaxis=dict(title='Z', range=axis_range),\n",
        "            aspectmode='cube'  # Ensures equal scaling\n",
        "        ),\n",
        "        width=1000,\n",
        "        height=1000,\n",
        "        showlegend=show_legend\n",
        "    )\n",
        "\n",
        "    plotly_div = fig.to_html(full_html=False, include_plotlyjs=False, div_id=\"scatter-plot-3d\")\n",
        "\n",
        "    javascript_code = f\"\"\"\n",
        "    <script>\n",
        "        function displayImage(imageId) {{\n",
        "            var imageElement = document.getElementById('image-display');\n",
        "            var placeholderText = document.getElementById('placeholder-text');\n",
        "            var imageDataURIs = {image_data_uris};\n",
        "            imageElement.src = imageDataURIs[imageId];\n",
        "            imageElement.style.display = 'block';\n",
        "            placeholderText.style.display = 'none';\n",
        "        }}\n",
        "\n",
        "        var chartElement = document.getElementById('scatter-plot-3d');\n",
        "\n",
        "        chartElement.on('plotly_click', function(data) {{\n",
        "            var customdata = data.points[0].customdata;\n",
        "            displayImage(customdata);\n",
        "        }});\n",
        "    </script>\n",
        "    \"\"\"\n",
        "\n",
        "    html_template = f\"\"\"\n",
        "    <!DOCTYPE html>\n",
        "    <html>\n",
        "        <head>\n",
        "            <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>\n",
        "            <style>\n",
        "                #image-container {{\n",
        "                    position: fixed;\n",
        "                    top: 0;\n",
        "                    left: 0;\n",
        "                    width: 200px;\n",
        "                    height: 200px;\n",
        "                    padding: 5px;\n",
        "                    border: 1px solid #ccc;\n",
        "                    background-color: white;\n",
        "                    z-index: 1000;\n",
        "                    box-sizing: border-box;\n",
        "                    display: flex;\n",
        "                    align-items: center;\n",
        "                    justify-content: center;\n",
        "                    text-align: center;\n",
        "                }}\n",
        "                #image-display {{\n",
        "                    width: 100%;\n",
        "                    height: 100%;\n",
        "                    object-fit: contain;\n",
        "                }}\n",
        "            </style>\n",
        "        </head>\n",
        "        <body>\n",
        "            {plotly_div}\n",
        "            <div id=\"image-container\">\n",
        "                <img id=\"image-display\" src=\"\" alt=\"Selected image\" style=\"display: none;\" />\n",
        "                <p id=\"placeholder-text\">Click on a data entry to display an image</p>\n",
        "            </div>\n",
        "            {javascript_code}\n",
        "        </body>\n",
        "    </html>\n",
        "    \"\"\"\n",
        "\n",
        "    display(HTML(html_template))\n",
        "\n",
        "display_projections(clusters, projections, crops)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ka1H-BQk8LAq"
      },
      "source": [
        "**Note:** ‰∏∫‰∫ÜÁÆÄÂåñ SigLIP, UMAP, Âíå KMeans combo, Ë∞ÉÁî®‰∫ÜÊâìÂåÖÂ•ΩÁöÑ [`TeamClassifier`](https://github.com/roboflow/sports/blob/06053616f1f8a8ae1fa936eb00dcdc2e4f888bb1/sports/common/team.py#L41)Ê®°Âûã ÂèØ‰ª•Âú® [sports](https://github.com/roboflow/sports) ‰∏≠ÊâæÂà∞."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ZG1DorZ8lSQ"
      },
      "outputs": [],
      "source": [
        "import supervision as sv\n",
        "from tqdm import tqdm\n",
        "from sports.common.team import TeamClassifier\n",
        "SOURCE_VIDEO_PATH = \"/content/08fd33_0.mp4\"\n",
        "PLAYER_ID = 2\n",
        "STRIDE = 30\n",
        "\n",
        "frame_generator = sv.get_video_frames_generator(\n",
        "    source_path=SOURCE_VIDEO_PATH, stride=STRIDE)\n",
        "\n",
        "crops = []\n",
        "for frame in tqdm(frame_generator, desc='collecting crops'):\n",
        "    result = PLAYER_DETECTION_MODEL.infer(frame, confidence=0.3)[0]\n",
        "    detections = sv.Detections.from_inference(result)\n",
        "    players_detections = detections[detections.class_id == PLAYER_ID]\n",
        "    players_crops = [sv.crop_image(frame, xyxy) for xyxy in detections.xyxy]\n",
        "    crops += players_crops\n",
        "\n",
        "team_classifier = TeamClassifier(device=\"cuda\")\n",
        "team_classifier.fit(crops)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WlHrjbIf-Yrk"
      },
      "source": [
        "**Note:** ‰∏∫ÂÆàÈó®ÂëòÊ∑ªÂä†Èòü‰ºçÊ†áÁ≠æ. ËÆ°ÁÆóÈòü‰ºçÁöÑÂπ≥Âùá‰ΩçÁΩÆÂ∞ÜÂÆàÈó®ÂëòÂ∞±ËøëÂàÜÈÖç"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qx_4g2DGC1Bd"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import supervision as sv\n",
        "\n",
        "def resolve_goalkeepers_team_id(\n",
        "    players: sv.Detections,\n",
        "    goalkeepers: sv.Detections\n",
        ") -> np.ndarray:\n",
        "    goalkeepers_xy = goalkeepers.get_anchors_coordinates(sv.Position.BOTTOM_CENTER)\n",
        "    players_xy = players.get_anchors_coordinates(sv.Position.BOTTOM_CENTER)\n",
        "    team_0_centroid = players_xy[players.class_id == 0].mean(axis=0)\n",
        "    team_1_centroid = players_xy[players.class_id == 1].mean(axis=0)\n",
        "    goalkeepers_team_id = []\n",
        "    for goalkeeper_xy in goalkeepers_xy:\n",
        "        dist_0 = np.linalg.norm(goalkeeper_xy - team_0_centroid)\n",
        "        dist_1 = np.linalg.norm(goalkeeper_xy - team_1_centroid)\n",
        "        goalkeepers_team_id.append(0 if dist_0 < dist_1 else 1)\n",
        "\n",
        "    return np.array(goalkeepers_team_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ÁîüÊàêÂÆåÊï¥ËßÜÈ¢ë"
      ],
      "metadata": {
        "id": "xo_1B4Ijxnsd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iwmQrEOHAPyi"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "import contextlib\n",
        "import io\n",
        "\n",
        "TARGET_VIDEO_PATH = \"/content/08fd33_0_result_4.mp4\"\n",
        "BALL_ID = 0\n",
        "GOALKEEPER_ID = 1\n",
        "PLAYER_ID = 2\n",
        "REFEREE_ID = 3\n",
        "\n",
        "video_info = sv.VideoInfo.from_video_path(SOURCE_VIDEO_PATH)\n",
        "frame_generator = sv.get_video_frames_generator(SOURCE_VIDEO_PATH)\n",
        "\n",
        "f = io.StringIO()\n",
        "\n",
        "with sv.VideoSink(target_path=TARGET_VIDEO_PATH, video_info=video_info) as sink:\n",
        "    # Â§ñÈÉ®ÁöÑ‰∏ªËøõÂ∫¶Êù°\n",
        "    for frame in tqdm(frame_generator, total=video_info.total_frames, desc='Processing Video'):\n",
        "\n",
        "        # ‰ΩøÁî® contextlib Â∞Ü stdout Âíå stderr ÈáçÂÆöÂêëÂà∞Êàë‰ª¨ÂàõÂª∫ÁöÑ StringIO ÂØπË±° f ‰∏≠\n",
        "        with contextlib.redirect_stdout(f), contextlib.redirect_stderr(f):\n",
        "            result = PLAYER_DETECTION_MODEL.infer(frame, confidence=0.3)[0]\n",
        "            detections = sv.Detections.from_inference(result)\n",
        "\n",
        "            ball_detections = detections[detections.class_id == BALL_ID]\n",
        "            ball_detections.xyxy = sv.pad_boxes(xyxy=ball_detections.xyxy, px=10)\n",
        "\n",
        "            all_detections = detections[detections.class_id != BALL_ID]\n",
        "            all_detections = all_detections.with_nms(threshold=0.5, class_agnostic=True)\n",
        "            all_detections = tracker.update_with_detections(detections=all_detections)\n",
        "\n",
        "            goalkeepers_detections = all_detections[all_detections.class_id == GOALKEEPER_ID]\n",
        "            players_detections = all_detections[all_detections.class_id == PLAYER_ID]\n",
        "            referees_detections = all_detections[all_detections.class_id == REFEREE_ID]\n",
        "\n",
        "            if len(players_detections) > 0:\n",
        "                players_crops = [sv.crop_image(frame, xyxy) for xyxy in players_detections.xyxy]\n",
        "                # ËøôÈáåÁöÑ predict ÂÜÖÈÉ®ËøõÂ∫¶Êù°‰πü‰ºöË¢´Âê∏ÂÖ• f ‰∏≠\n",
        "                players_detections.class_id = team_classifier.predict(players_crops)\n",
        "\n",
        "        # ÈÄªËæëÁªßÁª≠\n",
        "        if len(goalkeepers_detections) > 0:\n",
        "            goalkeepers_detections.class_id = resolve_goalkeepers_team_id(players_detections, goalkeepers_detections)\n",
        "\n",
        "        referees_detections.class_id -= 1\n",
        "        all_detections = sv.Detections.merge([players_detections, goalkeepers_detections, referees_detections])\n",
        "\n",
        "        labels = [f\"#{tid}\" for tid in all_detections.tracker_id] if all_detections.tracker_id is not None else []\n",
        "        all_detections.class_id = all_detections.class_id.astype(int)\n",
        "\n",
        "        annotated_frame = frame.copy()\n",
        "        annotated_frame = ellipse_annotator.annotate(scene=annotated_frame, detections=all_detections)\n",
        "        annotated_frame = label_annotator.annotate(scene=annotated_frame, detections=all_detections, labels=labels)\n",
        "        annotated_frame = triangle_annotator.annotate(scene=annotated_frame, detections=ball_detections)\n",
        "\n",
        "        sink.write_frame(annotated_frame)\n",
        "\n",
        "print(f\"\\nÂ§ÑÁêÜÂÆåÊàêÔºÅËßÜÈ¢ë‰øùÂ≠òÂú®: {TARGET_VIDEO_PATH}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4F_9d1YHKuj"
      },
      "source": [
        "#Âõõ„ÄÅÁêÉÂú∫ÂÖ≥ÈîÆÁÇπÊ£ÄÊµã"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ts9f1goyCPEa"
      },
      "outputs": [],
      "source": [
        "from inference import get_model\n",
        "from google.colab import userdata\n",
        "\n",
        "ROBOFLOW_API_KEY = userdata.get('ROBOFLOW_API_KEY')\n",
        "FIELD_DETECTION_MODEL_ID = \"football-field-detection-f07vi/14\"\n",
        "FIELD_DETECTION_MODEL = get_model(model_id=FIELD_DETECTION_MODEL_ID, api_key=ROBOFLOW_API_KEY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xhiFgOGkUky5"
      },
      "outputs": [],
      "source": [
        "import supervision as sv\n",
        "\n",
        "SOURCE_VIDEO_PATH = \"/content/121364_0.mp4\"\n",
        "\n",
        "vertex_annotator = sv.VertexAnnotator(\n",
        "    color=sv.Color.from_hex('#FF1493'),\n",
        "    radius=8)\n",
        "\n",
        "frame_generator = sv.get_video_frames_generator(SOURCE_VIDEO_PATH)\n",
        "frame = next(frame_generator)\n",
        "\n",
        "result = FIELD_DETECTION_MODEL.infer(frame, confidence=0.3)[0]\n",
        "key_points = sv.KeyPoints.from_inference(result)\n",
        "\n",
        "annotated_frame = frame.copy()\n",
        "annotated_frame = vertex_annotator.annotate(\n",
        "    scene=annotated_frame,\n",
        "    key_points=key_points)\n",
        "\n",
        "sv.plot_image(annotated_frame)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2HAVEmruAGpQ"
      },
      "source": [
        "**Note:** ËøáÊª§‰ΩéÁΩÆ‰ø°Â∫¶ÁöÑÁÇπ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X4XW4_bDGjlF"
      },
      "outputs": [],
      "source": [
        "import supervision as sv\n",
        "\n",
        "SOURCE_VIDEO_PATH = \"/content/121364_0.mp4\"\n",
        "\n",
        "vertex_annotator = sv.VertexAnnotator(\n",
        "    color=sv.Color.from_hex('#FF1493'),\n",
        "    radius=8)\n",
        "\n",
        "frame_generator = sv.get_video_frames_generator(SOURCE_VIDEO_PATH)\n",
        "frame = next(frame_generator)\n",
        "\n",
        "result = FIELD_DETECTION_MODEL.infer(frame, confidence=0.3)[0]\n",
        "key_points = sv.KeyPoints.from_inference(result)\n",
        "\n",
        "filter = key_points.confidence[0] > 0.5\n",
        "frame_reference_points = key_points.xy[0][filter]\n",
        "frame_reference_key_points = sv.KeyPoints(\n",
        "    xy=frame_reference_points[np.newaxis, ...])\n",
        "\n",
        "annotated_frame = frame.copy()\n",
        "annotated_frame = vertex_annotator.annotate(\n",
        "    scene=annotated_frame,\n",
        "    key_points=frame_reference_key_points)\n",
        "\n",
        "sv.plot_image(annotated_frame)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V7SUQtqbZ5QJ"
      },
      "source": [
        "## project pitch lines on frame"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ojlmrERnBAIN"
      },
      "source": [
        "**Note:** Ë∞ÉÁî®[sports](https://github.com/roboflow/sports)ÈáåÁöÑ[`SoccerPitchConfiguration`](https://github.com/roboflow/sports/blob/06053616f1f8a8ae1fa936eb00dcdc2e4f888bb1/sports/configs/soccer.py#L6) ÁîüÊàêÊ†áÂáÜË∂≥ÁêÉÂú∫"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G5y4tMWbaiC6"
      },
      "outputs": [],
      "source": [
        "from sports.annotators.soccer import draw_pitch\n",
        "from sports.configs.soccer import SoccerPitchConfiguration\n",
        "\n",
        "CONFIG = SoccerPitchConfiguration()\n",
        "\n",
        "annotated_frame = draw_pitch(CONFIG)\n",
        "\n",
        "sv.plot_image(annotated_frame)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1abHrITPB3Bd"
      },
      "source": [
        "**Note:** Â∞ÜÊ†áÂáÜË∂≥ÁêÉÂú∫ÊäïÂΩ±Âà∞ËßÜÈ¢ë‰∏≠[sports](https://github.com/roboflow/sports) Êèê‰æõ‰∫ÜÊâÄÈúÄÂ∑•ÂÖ∑ [`ViewTransformer`](https://github.com/roboflow/sports/blob/06053616f1f8a8ae1fa936eb00dcdc2e4f888bb1/sports/common/view.py#L7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kjoG33jod7M8"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import supervision as sv\n",
        "from tqdm.notebook import tqdm\n",
        "import contextlib\n",
        "\n",
        "SOURCE_VIDEO_PATH = \"/content/08fd33_0.mp4\"\n",
        "TARGET_VIDEO_PATH = \"/content/08fd33_0_result_with_pitch.mp4\"\n",
        "\n",
        "video_info = sv.VideoInfo.from_video_path(SOURCE_VIDEO_PATH)\n",
        "frame_generator = sv.get_video_frames_generator(SOURCE_VIDEO_PATH)\n",
        "\n",
        "ellipse_annotator = sv.EllipseAnnotator(color=sv.ColorPalette.from_hex(['#00BFFF', '#FF1493', '#FFD700']), thickness=2)\n",
        "edge_annotator = sv.EdgeAnnotator(color=sv.Color.from_hex('#00BFFF'), thickness=2, edges=CONFIG.edges)\n",
        "\n",
        "tracker = sv.ByteTrack()\n",
        "tracker.reset()\n",
        "\n",
        "with sv.VideoSink(target_path=TARGET_VIDEO_PATH, video_info=video_info) as sink:\n",
        "    for frame in tqdm(frame_generator, total=video_info.total_frames, desc='Full Video Processing'):\n",
        "\n",
        "        with contextlib.redirect_stdout(None), contextlib.redirect_stderr(None):\n",
        "            player_result = PLAYER_DETECTION_MODEL.infer(frame, confidence=0.3)[0]\n",
        "            field_result = FIELD_DETECTION_MODEL.infer(frame, confidence=0.3)[0]\n",
        "\n",
        "        detections = sv.Detections.from_inference(player_result)\n",
        "        key_points = sv.KeyPoints.from_inference(field_result)\n",
        "\n",
        "        filter = key_points.confidence[0] > 0.5\n",
        "        if np.sum(filter) >=4:\n",
        "            frame_ref_points = key_points.xy[0][filter]\n",
        "            pitch_ref_points = np.array(CONFIG.vertices)[filter]\n",
        "\n",
        "            transformer = ViewTransformer(source=pitch_ref_points, target=frame_ref_points)\n",
        "\n",
        "            pitch_all_points = np.array(CONFIG.vertices)\n",
        "            frame_all_points = transformer.transform_points(points=pitch_all_points)\n",
        "            frame_all_key_points = sv.KeyPoints(xy=frame_all_points[np.newaxis, ...])\n",
        "        else:\n",
        "            frame_all_key_points = None\n",
        "\n",
        "        all_detections = detections[detections.class_id != BALL_ID]\n",
        "        all_detections = tracker.update_with_detections(detections=all_detections)\n",
        "\n",
        "        annotated_frame = frame.copy()\n",
        "\n",
        "        if frame_all_key_points:\n",
        "            annotated_frame = edge_annotator.annotate(scene=annotated_frame, key_points=frame_all_key_points)\n",
        "\n",
        "        annotated_frame = ellipse_annotator.annotate(scene=annotated_frame, detections=all_detections)\n",
        "\n",
        "        sink.write_frame(annotated_frame)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8oMXo5k3HkzD"
      },
      "source": [
        "## ÂàõÂª∫Â∞èÂú∞Âõæ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B9nRbJnksPyE"
      },
      "outputs": [],
      "source": [
        "import supervision as sv\n",
        "from tqdm import tqdm\n",
        "from sports.common.team import TeamClassifier\n",
        "\n",
        "SOURCE_VIDEO_PATH = \"/content/08fd33_0.mp4\"\n",
        "PLAYER_ID = 2\n",
        "STRIDE = 30\n",
        "\n",
        "frame_generator = sv.get_video_frames_generator(\n",
        "    source_path=SOURCE_VIDEO_PATH, stride=STRIDE)\n",
        "\n",
        "crops = []\n",
        "for frame in tqdm(frame_generator, desc='collecting crops'):\n",
        "    result = PLAYER_DETECTION_MODEL.infer(frame, confidence=0.3)[0]\n",
        "    detections = sv.Detections.from_inference(result)\n",
        "    players_detections = detections[detections.class_id == PLAYER_ID]\n",
        "    players_crops = [sv.crop_image(frame, xyxy) for xyxy in detections.xyxy]\n",
        "    crops += players_crops\n",
        "\n",
        "team_classifier = TeamClassifier(device=\"cuda\")\n",
        "team_classifier.fit(crops)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "VoronoiÂõæ"
      ],
      "metadata": {
        "id": "Kia5rqZVCS2H"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X0s4SjLIJUwM"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "from typing import Optional\n",
        "\n",
        "def draw_pitch_voronoi_diagram_2(\n",
        "    config: SoccerPitchConfiguration,\n",
        "    team_1_xy: np.ndarray,\n",
        "    team_2_xy: np.ndarray,\n",
        "    team_1_color: sv.Color = sv.Color.RED,\n",
        "    team_2_color: sv.Color = sv.Color.WHITE,\n",
        "    opacity: float = 0.5,\n",
        "    padding: int = 50,\n",
        "    scale: float = 0.1,\n",
        "    pitch: Optional[np.ndarray] = None\n",
        ") -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Draws a Voronoi diagram on a soccer pitch representing the control areas of two\n",
        "    teams with smooth color transitions.\n",
        "\n",
        "    Args:\n",
        "        config (SoccerPitchConfiguration): Configuration object containing the\n",
        "            dimensions and layout of the pitch.\n",
        "        team_1_xy (np.ndarray): Array of (x, y) coordinates representing the positions\n",
        "            of players in team 1.\n",
        "        team_2_xy (np.ndarray): Array of (x, y) coordinates representing the positions\n",
        "            of players in team 2.\n",
        "        team_1_color (sv.Color, optional): Color representing the control area of\n",
        "            team 1. Defaults to sv.Color.RED.\n",
        "        team_2_color (sv.Color, optional): Color representing the control area of\n",
        "            team 2. Defaults to sv.Color.WHITE.\n",
        "        opacity (float, optional): Opacity of the Voronoi diagram overlay.\n",
        "            Defaults to 0.5.\n",
        "        padding (int, optional): Padding around the pitch in pixels.\n",
        "            Defaults to 50.\n",
        "        scale (float, optional): Scaling factor for the pitch dimensions.\n",
        "            Defaults to 0.1.\n",
        "        pitch (Optional[np.ndarray], optional): Existing pitch image to draw the\n",
        "            Voronoi diagram on. If None, a new pitch will be created. Defaults to None.\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: Image of the soccer pitch with the Voronoi diagram overlay.\n",
        "    \"\"\"\n",
        "    if pitch is None:\n",
        "        pitch = draw_pitch(\n",
        "            config=config,\n",
        "            padding=padding,\n",
        "            scale=scale\n",
        "        )\n",
        "\n",
        "    scaled_width = int(config.width * scale)\n",
        "    scaled_length = int(config.length * scale)\n",
        "\n",
        "    voronoi = np.zeros_like(pitch, dtype=np.uint8)\n",
        "\n",
        "    team_1_color_bgr = np.array(team_1_color.as_bgr(), dtype=np.uint8)\n",
        "    team_2_color_bgr = np.array(team_2_color.as_bgr(), dtype=np.uint8)\n",
        "\n",
        "    y_coordinates, x_coordinates = np.indices((\n",
        "        scaled_width + 2 * padding,\n",
        "        scaled_length + 2 * padding\n",
        "    ))\n",
        "\n",
        "    y_coordinates -= padding\n",
        "    x_coordinates -= padding\n",
        "\n",
        "    def calculate_distances(xy, x_coordinates, y_coordinates):\n",
        "        return np.sqrt((xy[:, 0][:, None, None] * scale - x_coordinates) ** 2 +\n",
        "                       (xy[:, 1][:, None, None] * scale - y_coordinates) ** 2)\n",
        "\n",
        "    distances_team_1 = calculate_distances(team_1_xy, x_coordinates, y_coordinates)\n",
        "    distances_team_2 = calculate_distances(team_2_xy, x_coordinates, y_coordinates)\n",
        "\n",
        "    min_distances_team_1 = np.min(distances_team_1, axis=0)\n",
        "    min_distances_team_2 = np.min(distances_team_2, axis=0)\n",
        "\n",
        "    # Increase steepness of the blend effect\n",
        "    steepness = 15  # Increased steepness for sharper transition\n",
        "    distance_ratio = min_distances_team_2 / np.clip(min_distances_team_1 + min_distances_team_2, a_min=1e-5, a_max=None)\n",
        "    blend_factor = np.tanh((distance_ratio - 0.5) * steepness) * 0.5 + 0.5\n",
        "\n",
        "    # Create the smooth color transition\n",
        "    for c in range(3):  # Iterate over the B, G, R channels\n",
        "        voronoi[:, :, c] = (blend_factor * team_1_color_bgr[c] +\n",
        "                            (1 - blend_factor) * team_2_color_bgr[c]).astype(np.uint8)\n",
        "\n",
        "    overlay = cv2.addWeighted(voronoi, opacity, pitch, 1 - opacity, 0)\n",
        "\n",
        "    return overlay"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ÂçïÂ∏ß"
      ],
      "metadata": {
        "id": "5QWiZ5o2El16"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import supervision as sv\n",
        "from sports.annotators.soccer import (\n",
        "    draw_pitch,\n",
        "    draw_points_on_pitch,\n",
        "    draw_pitch_voronoi_diagram\n",
        ")\n",
        "\n",
        "SOURCE_VIDEO_PATH = \"/content/08fd33_0.mp4\"\n",
        "BALL_ID = 0\n",
        "GOALKEEPER_ID = 1\n",
        "PLAYER_ID = 2\n",
        "REFEREE_ID = 3\n",
        "\n",
        "ellipse_annotator = sv.EllipseAnnotator(\n",
        "    color=sv.ColorPalette.from_hex(['#00BFFF', '#FF1493', '#FFD700']),\n",
        "    thickness=2\n",
        ")\n",
        "label_annotator = sv.LabelAnnotator(\n",
        "    color=sv.ColorPalette.from_hex(['#00BFFF', '#FF1493', '#FFD700']),\n",
        "    text_color=sv.Color.from_hex('#000000'),\n",
        "    text_position=sv.Position.BOTTOM_CENTER\n",
        ")\n",
        "triangle_annotator = sv.TriangleAnnotator(\n",
        "    color=sv.Color.from_hex('#FFD700'),\n",
        "    base=20, height=17\n",
        ")\n",
        "\n",
        "tracker = sv.ByteTrack()\n",
        "tracker.reset()\n",
        "\n",
        "frame_generator = sv.get_video_frames_generator(SOURCE_VIDEO_PATH)\n",
        "frame = next(frame_generator)\n",
        "\n",
        "# ball, goalkeeper, player, referee detection\n",
        "\n",
        "result = PLAYER_DETECTION_MODEL.infer(frame, confidence=0.3)[0]\n",
        "detections = sv.Detections.from_inference(result)\n",
        "\n",
        "ball_detections = detections[detections.class_id == BALL_ID]\n",
        "ball_detections.xyxy = sv.pad_boxes(xyxy=ball_detections.xyxy, px=10)\n",
        "\n",
        "all_detections = detections[detections.class_id != BALL_ID]\n",
        "all_detections = all_detections.with_nms(threshold=0.5, class_agnostic=True)\n",
        "all_detections = tracker.update_with_detections(detections=all_detections)\n",
        "\n",
        "goalkeepers_detections = all_detections[all_detections.class_id == GOALKEEPER_ID]\n",
        "players_detections = all_detections[all_detections.class_id == PLAYER_ID]\n",
        "referees_detections = all_detections[all_detections.class_id == REFEREE_ID]\n",
        "\n",
        "# team assignment\n",
        "\n",
        "players_crops = [sv.crop_image(frame, xyxy) for xyxy in players_detections.xyxy]\n",
        "players_detections.class_id = team_classifier.predict(players_crops)\n",
        "\n",
        "goalkeepers_detections.class_id = resolve_goalkeepers_team_id(\n",
        "    players_detections, goalkeepers_detections)\n",
        "\n",
        "referees_detections.class_id -= 1\n",
        "\n",
        "all_detections = sv.Detections.merge([\n",
        "    players_detections, goalkeepers_detections, referees_detections])\n",
        "\n",
        "# frame visualization\n",
        "\n",
        "labels = [\n",
        "    f\"#{tracker_id}\"\n",
        "    for tracker_id\n",
        "    in all_detections.tracker_id\n",
        "]\n",
        "\n",
        "all_detections.class_id = all_detections.class_id.astype(int)\n",
        "\n",
        "annotated_frame = frame.copy()\n",
        "annotated_frame = ellipse_annotator.annotate(\n",
        "    scene=annotated_frame,\n",
        "    detections=all_detections)\n",
        "annotated_frame = label_annotator.annotate(\n",
        "    scene=annotated_frame,\n",
        "    detections=all_detections,\n",
        "    labels=labels)\n",
        "annotated_frame = triangle_annotator.annotate(\n",
        "    scene=annotated_frame,\n",
        "    detections=ball_detections)\n",
        "\n",
        "sv.plot_image(annotated_frame)\n",
        "\n",
        "players_detections = sv.Detections.merge([\n",
        "    players_detections, goalkeepers_detections\n",
        "])\n",
        "\n",
        "# detect pitch key points\n",
        "\n",
        "result = FIELD_DETECTION_MODEL.infer(frame, confidence=0.3)[0]\n",
        "key_points = sv.KeyPoints.from_inference(result)\n",
        "\n",
        "# project ball, players and referies on pitch\n",
        "\n",
        "filter = key_points.confidence[0] > 0.5\n",
        "frame_reference_points = key_points.xy[0][filter]\n",
        "pitch_reference_points = np.array(CONFIG.vertices)[filter]\n",
        "\n",
        "transformer = ViewTransformer(\n",
        "    source=frame_reference_points,\n",
        "    target=pitch_reference_points\n",
        ")\n",
        "\n",
        "frame_ball_xy = ball_detections.get_anchors_coordinates(sv.Position.BOTTOM_CENTER)\n",
        "pitch_ball_xy = transformer.transform_points(points=frame_ball_xy)\n",
        "\n",
        "players_xy = players_detections.get_anchors_coordinates(sv.Position.BOTTOM_CENTER)\n",
        "pitch_players_xy = transformer.transform_points(points=players_xy)\n",
        "\n",
        "referees_xy = referees_detections.get_anchors_coordinates(sv.Position.BOTTOM_CENTER)\n",
        "pitch_referees_xy = transformer.transform_points(points=referees_xy)\n",
        "\n",
        "# visualize video game-style radar view\n",
        "\n",
        "annotated_frame = draw_pitch(CONFIG)\n",
        "annotated_frame = draw_points_on_pitch(\n",
        "    config=CONFIG,\n",
        "    xy=pitch_ball_xy,\n",
        "    face_color=sv.Color.WHITE,\n",
        "    edge_color=sv.Color.BLACK,\n",
        "    radius=10,\n",
        "    pitch=annotated_frame)\n",
        "annotated_frame = draw_points_on_pitch(\n",
        "    config=CONFIG,\n",
        "    xy=pitch_players_xy[players_detections.class_id == 0],\n",
        "    face_color=sv.Color.from_hex('00BFFF'),\n",
        "    edge_color=sv.Color.BLACK,\n",
        "    radius=16,\n",
        "    pitch=annotated_frame)\n",
        "annotated_frame = draw_points_on_pitch(\n",
        "    config=CONFIG,\n",
        "    xy=pitch_players_xy[players_detections.class_id == 1],\n",
        "    face_color=sv.Color.from_hex('FF1493'),\n",
        "    edge_color=sv.Color.BLACK,\n",
        "    radius=16,\n",
        "    pitch=annotated_frame)\n",
        "annotated_frame = draw_points_on_pitch(\n",
        "    config=CONFIG,\n",
        "    xy=pitch_referees_xy,\n",
        "    face_color=sv.Color.from_hex('FFD700'),\n",
        "    edge_color=sv.Color.BLACK,\n",
        "    radius=16,\n",
        "    pitch=annotated_frame)\n",
        "\n",
        "sv.plot_image(annotated_frame)\n",
        "\n",
        "# visualize voronoi diagram\n",
        "\n",
        "annotated_frame = draw_pitch(CONFIG)\n",
        "annotated_frame = draw_pitch_voronoi_diagram(\n",
        "    config=CONFIG,\n",
        "    team_1_xy=pitch_players_xy[players_detections.class_id == 0],\n",
        "    team_2_xy=pitch_players_xy[players_detections.class_id == 1],\n",
        "    team_1_color=sv.Color.from_hex('00BFFF'),\n",
        "    team_2_color=sv.Color.from_hex('FF1493'),\n",
        "    pitch=annotated_frame)\n",
        "\n",
        "sv.plot_image(annotated_frame)\n",
        "\n",
        "# visualize voronoi diagram with blend\n",
        "\n",
        "annotated_frame = draw_pitch(\n",
        "    config=CONFIG,\n",
        "    background_color=sv.Color.WHITE,\n",
        "    line_color=sv.Color.BLACK\n",
        ")\n",
        "annotated_frame = draw_pitch_voronoi_diagram_2(\n",
        "    config=CONFIG,\n",
        "    team_1_xy=pitch_players_xy[players_detections.class_id == 0],\n",
        "    team_2_xy=pitch_players_xy[players_detections.class_id == 1],\n",
        "    team_1_color=sv.Color.from_hex('00BFFF'),\n",
        "    team_2_color=sv.Color.from_hex('FF1493'),\n",
        "    pitch=annotated_frame)\n",
        "annotated_frame = draw_points_on_pitch(\n",
        "    config=CONFIG,\n",
        "    xy=pitch_ball_xy,\n",
        "    face_color=sv.Color.WHITE,\n",
        "    edge_color=sv.Color.WHITE,\n",
        "    radius=8,\n",
        "    thickness=1,\n",
        "    pitch=annotated_frame)\n",
        "annotated_frame = draw_points_on_pitch(\n",
        "    config=CONFIG,\n",
        "    xy=pitch_players_xy[players_detections.class_id == 0],\n",
        "    face_color=sv.Color.from_hex('00BFFF'),\n",
        "    edge_color=sv.Color.WHITE,\n",
        "    radius=16,\n",
        "    thickness=1,\n",
        "    pitch=annotated_frame)\n",
        "annotated_frame = draw_points_on_pitch(\n",
        "    config=CONFIG,\n",
        "    xy=pitch_players_xy[players_detections.class_id == 1],\n",
        "    face_color=sv.Color.from_hex('FF1493'),\n",
        "    edge_color=sv.Color.WHITE,\n",
        "    radius=16,\n",
        "    thickness=1,\n",
        "    pitch=annotated_frame)\n",
        "\n",
        "sv.plot_image(annotated_frame)"
      ],
      "metadata": {
        "id": "NJX9Wil2EibV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ËßÜÈ¢ë"
      ],
      "metadata": {
        "id": "YUPKf_nHEoei"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6rjfNfzErrSN"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import supervision as sv\n",
        "from tqdm import tqdm\n",
        "import cv2\n",
        "import contextlib\n",
        "import io\n",
        "from google.colab import files\n",
        "\n",
        "# 1. ËÆæÁΩÆË∑ØÂæÑ\n",
        "SOURCE_VIDEO_PATH = \"/content/08fd33_0.mp4\"\n",
        "TARGET_VIDEO_PATH = \"/content/108fd33_0_analysis_result.mp4\"\n",
        "# ÂÆö‰πâÂ∞èÂú∞ÂõæÂú®‰∏ªÂõæ‰∏≠ÁöÑÊØî‰æã (0.3 Ë°®Á§∫Âç†ÂÆΩÂ∫¶ÁöÑ 30%)\n",
        "MINIMAP_SCALE = 0.35\n",
        "\n",
        "video_info = sv.VideoInfo.from_video_path(SOURCE_VIDEO_PATH)\n",
        "frame_generator = sv.get_video_frames_generator(SOURCE_VIDEO_PATH)\n",
        "\n",
        "# ÈáçÁΩÆË∑üË∏™Âô®\n",
        "tracker = sv.ByteTrack()\n",
        "tracker.reset()\n",
        "\n",
        "with sv.VideoSink(target_path=TARGET_VIDEO_PATH, video_info=video_info) as sink:\n",
        "    for frame in tqdm(frame_generator, total=video_info.total_frames, desc='ÁîüÊàêÂàÜÊûêËßÜÈ¢ë'):\n",
        "\n",
        "        # --- [Ê≠•È™§ 1: Ê®°ÂûãÊé®ÁêÜ] ---\n",
        "        # Â±èËîΩ tqdm Âπ≤Êâ∞\n",
        "        with contextlib.redirect_stdout(io.StringIO()), contextlib.redirect_stderr(io.StringIO()):\n",
        "            player_result = PLAYER_DETECTION_MODEL.infer(frame, confidence=0.3)[0]\n",
        "            field_result = FIELD_DETECTION_MODEL.infer(frame, confidence=0.3)[0]\n",
        "\n",
        "        detections = sv.Detections.from_inference(player_result)\n",
        "        key_points = sv.KeyPoints.from_inference(field_result)\n",
        "\n",
        "        # --- [Ê≠•È™§ 2: ÁõÆÊ†áÂ§ÑÁêÜ‰∏éÂõ¢ÈòüÂàÜÁ±ª] ---\n",
        "        ball_detections = detections[detections.class_id == BALL_ID]\n",
        "        all_detections = detections[detections.class_id != BALL_ID]\n",
        "        all_detections = all_detections.with_nms(threshold=0.5)\n",
        "        all_detections = tracker.update_with_detections(all_detections)\n",
        "\n",
        "        players_detections = all_detections[all_detections.class_id == PLAYER_ID]\n",
        "        goalkeepers_detections = all_detections[all_detections.class_id == GOALKEEPER_ID]\n",
        "        referees_detections = all_detections[all_detections.class_id == REFEREE_ID]\n",
        "\n",
        "        if len(players_detections) > 0:\n",
        "            crops = [sv.crop_image(frame, xyxy) for xyxy in players_detections.xyxy]\n",
        "            players_detections.class_id = team_classifier.predict(crops)\n",
        "\n",
        "            if len(goalkeepers_detections) > 0:\n",
        "                goalkeepers_detections.class_id = resolve_goalkeepers_team_id(players_detections, goalkeepers_detections)\n",
        "\n",
        "        # --- [Ê≠•È™§ 3: ÂùêÊ†áËΩ¨Êç¢ (ÂÉèÁ¥† -> ÁêÉÂú∫)] ---\n",
        "        filter = key_points.confidence[0] > 0.5\n",
        "        if np.sum(filter) >= 4:\n",
        "            transformer = ViewTransformer(\n",
        "                source=key_points.xy[0][filter],\n",
        "                target=np.array(CONFIG.vertices)[filter]\n",
        "            )\n",
        "\n",
        "            # ÊèêÂèñÁêÉÂëòÂíåÁêÉÂú®Â∞èÂú∞Âõæ‰∏äÁöÑÂùêÊ†á\n",
        "            combined_players = sv.Detections.merge([players_detections, goalkeepers_detections])\n",
        "            p_coords = combined_players.get_anchors_coordinates(sv.Position.BOTTOM_CENTER)\n",
        "            pitch_players_xy = transformer.transform_points(p_coords)\n",
        "\n",
        "            b_coords = ball_detections.get_anchors_coordinates(sv.Position.BOTTOM_CENTER)\n",
        "            pitch_ball_xy = transformer.transform_points(b_coords)\n",
        "        else:\n",
        "            pitch_players_xy = None\n",
        "\n",
        "        # --- [Ê≠•È™§ 4: ÁªòÂà∂‰∏ªÁîªÈù¢] ---\n",
        "        annotated_frame = frame.copy()\n",
        "        # Áªü‰∏ÄÂêàÂπ∂Áî®‰∫éÁîªÊ§≠ÂúÜ\n",
        "        final_detections = sv.Detections.merge([players_detections, goalkeepers_detections, referees_detections])\n",
        "        annotated_frame = ellipse_annotator.annotate(scene=annotated_frame, detections=final_detections)\n",
        "        annotated_frame = triangle_annotator.annotate(scene=annotated_frame, detections=ball_detections)\n",
        "\n",
        "        # --- [Ê≠•È™§ 5: ÁªòÂà∂Â∞èÂú∞ÂõæÂπ∂ÂµåÂÖ• (Áîª‰∏≠Áîª)] ---\n",
        "        if pitch_players_xy is not None and len(pitch_players_xy) > 0:\n",
        "            # ÁªòÂà∂‰Ω†ÂñúÊ¨¢ÁöÑÂπ≥ÊªëÁª¥ËØ∫Âõæ\n",
        "            minimap = draw_pitch(CONFIG, background_color=sv.Color.WHITE, line_color=sv.Color.BLACK)\n",
        "            minimap = draw_pitch_voronoi_diagram_2(\n",
        "                config=CONFIG,\n",
        "                team_1_xy=pitch_players_xy[combined_players.class_id == 0],\n",
        "                team_2_xy=pitch_players_xy[combined_players.class_id == 1],\n",
        "                team_1_color=sv.Color.from_hex('00BFFF'),\n",
        "                team_2_color=sv.Color.from_hex('FF1493'),\n",
        "                pitch=minimap\n",
        "            )\n",
        "            # Âú®Áª¥ËØ∫Âõæ‰∏äÁîªÁÇπ\n",
        "            minimap = draw_points_on_pitch(config=CONFIG, xy=pitch_ball_xy, face_color=sv.Color.WHITE, radius=10, pitch=minimap)\n",
        "\n",
        "            # ËÆ°ÁÆóÁº©ÊîæÊØî‰æãÂπ∂Ë¶ÜÁõñÂà∞‰∏ªÂõæÂè≥‰∏äËßí\n",
        "            mm_h, mm_w, _ = minimap.shape\n",
        "            target_w = int(video_info.width * MINIMAP_SCALE)\n",
        "            target_h = int(mm_h * (target_w / mm_w))\n",
        "            resized_minimap = cv2.resize(minimap, (target_w, target_h))\n",
        "\n",
        "            # ÂµåÂÖ•‰ΩçÁΩÆÔºàÂè≥‰∏äËßíÔºåÁïôÂá∫ 20 ÂÉèÁ¥†ËæπË∑ùÔºâ\n",
        "            annotated_frame[20:20+target_h, video_info.width-target_w-20:video_info.width-20] = resized_minimap\n",
        "\n",
        "        # ÂÜôÂÖ•Â∏ß\n",
        "        sink.write_frame(annotated_frame)\n",
        "\n",
        "files.download(TARGET_VIDEO_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Â∞èÂú∞Âõæ"
      ],
      "metadata": {
        "id": "1kfXkqbrQv0-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import supervision as sv\n",
        "from tqdm import tqdm\n",
        "import cv2\n",
        "import contextlib\n",
        "import io\n",
        "\n",
        "# --- ÈÖçÁΩÆÂèÇÊï∞ ---\n",
        "SOURCE_VIDEO_PATH = \"/content/08fd33_0.mp4\"\n",
        "TARGET_VIDEO_PATH = \"/content/108fd33_0_analysis_result_2.mp4\"\n",
        "MINIMAP_SCALE = 0.30  # Èõ∑ËææÂõæÂç†‰∏ªËßÜÈ¢ëÂÆΩÂ∫¶ÁöÑ 30%\n",
        "MARGIN = 20           # Èõ∑ËææÂõæË∑ùÁ¶ªËæπÁºòÁöÑÂÉèÁ¥†\n",
        "\n",
        "video_info = sv.VideoInfo.from_video_path(SOURCE_VIDEO_PATH)\n",
        "frame_generator = sv.get_video_frames_generator(SOURCE_VIDEO_PATH)\n",
        "\n",
        "# ÈáçÁΩÆË∑üË∏™Âô®\n",
        "tracker = sv.ByteTrack()\n",
        "tracker.reset()\n",
        "\n",
        "with sv.VideoSink(target_path=TARGET_VIDEO_PATH, video_info=video_info) as sink:\n",
        "    for frame in tqdm(frame_generator, total=video_info.total_frames, desc='Ê≠£Âú®ÂêàÊàêÈõ∑ËææËßÜÈ¢ë'):\n",
        "\n",
        "        # 1. Ê®°ÂûãÊé®ÁêÜÔºàÂ±èËîΩÊùÇËÆØËæìÂá∫Ôºâ\n",
        "        with contextlib.redirect_stdout(io.StringIO()), contextlib.redirect_stderr(io.StringIO()):\n",
        "            player_result = PLAYER_DETECTION_MODEL.infer(frame, confidence=0.3)[0]\n",
        "            field_result = FIELD_DETECTION_MODEL.infer(frame, confidence=0.3)[0]\n",
        "\n",
        "        detections = sv.Detections.from_inference(player_result)\n",
        "        field_key_points = sv.KeyPoints.from_inference(field_result)\n",
        "\n",
        "        # 2. ÁêÉÂëòË∑üË∏™‰∏éÂàÜÁ±ª\n",
        "        ball_detections = detections[detections.class_id == BALL_ID]\n",
        "        all_detections = detections[detections.class_id != BALL_ID]\n",
        "        all_detections = all_detections.with_nms(threshold=0.5)\n",
        "        all_detections = tracker.update_with_detections(all_detections)\n",
        "\n",
        "        # Âå∫ÂàÜÁêÉÈòü\n",
        "        players_detections = all_detections[all_detections.class_id == PLAYER_ID]\n",
        "        goalkeepers_detections = all_detections[all_detections.class_id == GOALKEEPER_ID]\n",
        "        referees_detections = all_detections[all_detections.class_id == REFEREE_ID]\n",
        "\n",
        "        if len(players_detections) > 0:\n",
        "            crops = [sv.crop_image(frame, xyxy) for xyxy in players_detections.xyxy]\n",
        "            players_detections.class_id = team_classifier.predict(crops)\n",
        "            if len(goalkeepers_detections) > 0:\n",
        "                goalkeepers_detections.class_id = resolve_goalkeepers_team_id(players_detections, goalkeepers_detections)\n",
        "\n",
        "        # 3. Âá†‰ΩïÂèòÊç¢ (Áî®‰∫éÁîüÊàêÈõ∑ËææÂùêÊ†á)\n",
        "        filter = field_key_points.confidence[0] > 0.5\n",
        "        radar_ready = False\n",
        "        if np.sum(filter) >= 4:\n",
        "            transformer = ViewTransformer(\n",
        "                source=field_key_points.xy[0][filter],\n",
        "                target=np.array(CONFIG.vertices)[filter]\n",
        "            )\n",
        "            # Ëé∑ÂèñÊâÄÊúâÁêÉÂëòÂíåÁêÉÂú®Âπ≥Èù¢Âõæ‰∏äÁöÑÂùêÊ†á\n",
        "            combined_players = sv.Detections.merge([players_detections, goalkeepers_detections])\n",
        "            pitch_players_xy = transformer.transform_points(combined_players.get_anchors_coordinates(sv.Position.BOTTOM_CENTER))\n",
        "            pitch_ball_xy = transformer.transform_points(ball_detections.get_anchors_coordinates(sv.Position.BOTTOM_CENTER))\n",
        "            pitch_referees_xy = transformer.transform_points(referees_detections.get_anchors_coordinates(sv.Position.BOTTOM_CENTER))\n",
        "            radar_ready = True\n",
        "\n",
        "        # 4. ÁªòÂà∂‰∏ªÁîªÈù¢Ê†áÊ≥®\n",
        "        annotated_frame = frame.copy()\n",
        "        final_detections = sv.Detections.merge([players_detections, goalkeepers_detections, referees_detections])\n",
        "        labels = [f\"#{tid}\" for tid in final_detections.tracker_id]\n",
        "\n",
        "        annotated_frame = ellipse_annotator.annotate(scene=annotated_frame, detections=final_detections)\n",
        "        annotated_frame = label_annotator.annotate(scene=annotated_frame, detections=final_detections, labels=labels)\n",
        "        annotated_frame = triangle_annotator.annotate(scene=annotated_frame, detections=ball_detections)\n",
        "\n",
        "        # 5. ÁªòÂà∂Èõ∑ËææÂõæÂπ∂ÂµåÂÖ•\n",
        "        if radar_ready:\n",
        "            # ÂàõÂª∫Èõ∑ËææÂõæÂ∫ïÂõæ (FIFA È£éÊ†ºÔºöÁôΩÂ∫ïÈªëÁ∫øÊàñÁªèÂÖ∏ÁªøÂ∫ï)\n",
        "            radar_view = draw_pitch(CONFIG)\n",
        "\n",
        "            # Âú®Èõ∑Ëææ‰∏äÁîªÁêÉÂëò\n",
        "            for team_id, color in [(0, sv.Color.from_hex('00BFFF')), (1, sv.Color.from_hex('FF1493'))]:\n",
        "                mask = combined_players.class_id == team_id\n",
        "                if np.any(mask):\n",
        "                    radar_view = draw_points_on_pitch(\n",
        "                        config=CONFIG, xy=pitch_players_xy[mask],\n",
        "                        face_color=color, edge_color=sv.Color.BLACK, radius=12, pitch=radar_view)\n",
        "\n",
        "            # ÁîªË£ÅÂà§ÂíåÁêÉ\n",
        "            radar_view = draw_points_on_pitch(config=CONFIG, xy=pitch_referees_xy, face_color=sv.Color.from_hex('FFD700'), radius=12, pitch=radar_view)\n",
        "            radar_view = draw_points_on_pitch(config=CONFIG, xy=pitch_ball_xy, face_color=sv.Color.WHITE, edge_color=sv.Color.BLACK, radius=8, pitch=radar_view)\n",
        "\n",
        "            # Áº©ÊîæÈõ∑ËææÂõæ\n",
        "            mm_h, mm_w, _ = radar_view.shape\n",
        "            target_w = int(video_info.width * MINIMAP_SCALE)\n",
        "            target_h = int(mm_h * (target_w / mm_w))\n",
        "            resized_radar = cv2.resize(radar_view, (target_w, target_h))\n",
        "\n",
        "            # Ë¶ÜÁõñÂà∞‰∏ªÁîªÈù¢Âè≥‰∏äËßí\n",
        "            x_offset = video_info.width - target_w - MARGIN\n",
        "            y_offset = MARGIN\n",
        "            annotated_frame[y_offset:y_offset+target_h, x_offset:x_offset+target_w] = resized_radar\n",
        "\n",
        "        # 6. ÂÜôÂÖ•Â∏ß\n",
        "        sink.write_frame(annotated_frame)\n",
        "\n",
        "print(f\"ÊÅ≠ÂñúÔºÅÊàòÊúØÂàÜÊûêËßÜÈ¢ëÂ∑≤ÁîüÊàêÔºö{TARGET_VIDEO_PATH}\")"
      ],
      "metadata": {
        "id": "HmRxDNjMQzC0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQ7CP3RFoX4R"
      },
      "source": [
        "## Ë∂≥ÁêÉËΩ®Ëøπ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uFMa2ER_JUtG"
      },
      "outputs": [],
      "source": [
        "from collections import deque\n",
        "import supervision as sv\n",
        "from sports.annotators.soccer import draw_pitch, draw_points_on_pitch\n",
        "\n",
        "SOURCE_VIDEO_PATH = \"/content/121364_0.mp4\"\n",
        "BALL_ID = 0\n",
        "MAXLEN = 5\n",
        "\n",
        "video_info = sv.VideoInfo.from_video_path(SOURCE_VIDEO_PATH)\n",
        "frame_generator = sv.get_video_frames_generator(SOURCE_VIDEO_PATH)\n",
        "\n",
        "path_raw = []\n",
        "M = deque(maxlen=MAXLEN)\n",
        "\n",
        "for frame in tqdm(frame_generator, total=video_info.total_frames):\n",
        "\n",
        "    result = PLAYER_DETECTION_MODEL.infer(frame, confidence=0.3)[0]\n",
        "    detections = sv.Detections.from_inference(result)\n",
        "\n",
        "    ball_detections = detections[detections.class_id == BALL_ID]\n",
        "    ball_detections.xyxy = sv.pad_boxes(xyxy=ball_detections.xyxy, px=10)\n",
        "\n",
        "    result = FIELD_DETECTION_MODEL.infer(frame, confidence=0.3)[0]\n",
        "    key_points = sv.KeyPoints.from_inference(result)\n",
        "\n",
        "    filter = key_points.confidence[0] > 0.5\n",
        "    frame_reference_points = key_points.xy[0][filter]\n",
        "    pitch_reference_points = np.array(CONFIG.vertices)[filter]\n",
        "\n",
        "    transformer = ViewTransformer(\n",
        "        source=frame_reference_points,\n",
        "        target=pitch_reference_points\n",
        "    )\n",
        "    M.append(transformer.m)\n",
        "    transformer.m = np.mean(np.array(M), axis=0)\n",
        "\n",
        "    frame_ball_xy = ball_detections.get_anchors_coordinates(sv.Position.BOTTOM_CENTER)\n",
        "    pitch_ball_xy = transformer.transform_points(points=frame_ball_xy)\n",
        "\n",
        "    path_raw.append(pitch_ball_xy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CAD53KnFp8dw"
      },
      "outputs": [],
      "source": [
        "path = [\n",
        "    np.empty((0, 2), dtype=np.float32) if coorinates.shape[0] >= 2 else coorinates\n",
        "    for coorinates\n",
        "    in path_raw\n",
        "]\n",
        "\n",
        "path = [coorinates.flatten() for coorinates in path]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fwiq0zIAq2JE"
      },
      "outputs": [],
      "source": [
        "from sports.annotators.soccer import draw_paths_on_pitch\n",
        "\n",
        "annotated_frame = draw_pitch(CONFIG)\n",
        "annotated_frame = draw_paths_on_pitch(\n",
        "    config=CONFIG,\n",
        "    paths=[path],\n",
        "    color=sv.Color.WHITE,\n",
        "    pitch=annotated_frame)\n",
        "\n",
        "sv.plot_image(annotated_frame)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YWksgzo4q5cr"
      },
      "outputs": [],
      "source": [
        "from typing import List, Union\n",
        "\n",
        "def replace_outliers_based_on_distance(\n",
        "    positions: List[np.ndarray],\n",
        "    distance_threshold: float\n",
        ") -> List[np.ndarray]:\n",
        "    last_valid_position: Union[np.ndarray, None] = None\n",
        "    cleaned_positions: List[np.ndarray] = []\n",
        "\n",
        "    for position in positions:\n",
        "        if len(position) == 0:\n",
        "            # If the current position is already empty, just add it to the cleaned positions\n",
        "            cleaned_positions.append(position)\n",
        "        else:\n",
        "            if last_valid_position is None:\n",
        "                # If there's no valid last position, accept the first valid one\n",
        "                cleaned_positions.append(position)\n",
        "                last_valid_position = position\n",
        "            else:\n",
        "                # Calculate the distance from the last valid position\n",
        "                distance = np.linalg.norm(position - last_valid_position)\n",
        "                if distance > distance_threshold:\n",
        "                    # Replace with empty array if the distance exceeds the threshold\n",
        "                    cleaned_positions.append(np.array([], dtype=np.float64))\n",
        "                else:\n",
        "                    cleaned_positions.append(position)\n",
        "                    last_valid_position = position\n",
        "\n",
        "    return cleaned_positions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a0wmKU-qq7zP"
      },
      "outputs": [],
      "source": [
        "MAX_DISTANCE_THRESHOLD = 500\n",
        "\n",
        "path = replace_outliers_based_on_distance(path, MAX_DISTANCE_THRESHOLD)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wXL4eqOTrASQ"
      },
      "outputs": [],
      "source": [
        "from sports.annotators.soccer import draw_paths_on_pitch\n",
        "\n",
        "annotated_frame = draw_pitch(CONFIG)\n",
        "annotated_frame = draw_paths_on_pitch(\n",
        "    config=CONFIG,\n",
        "    paths=[path],\n",
        "    color=sv.Color.WHITE,\n",
        "    pitch=annotated_frame)\n",
        "\n",
        "sv.plot_image(annotated_frame)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}